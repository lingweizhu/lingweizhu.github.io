@article{ZHU2020CEP,
title = "Scalable reinforcement learning for plant-wide control of vinyl acetate monomer process",
journal = "Control Engineering Practice",
volume = "97",
pages = "104331-104340",
year = "2020",
author = "Lingwei Zhu and Yunduan Cui and Go Takami and Hiroaki Kanokogi and Takamitsu Matsubara",
keywords = "Chemical process control, Reinforcement learning, Vinyl acetate monomer",
abstract = "This paper explores a reinforcement learning (RL) approach that designs automatic control strategies in a large-scale chemical process control scenario as the first step for leveraging an RL method to intelligently control real-world chemical plants. The huge number of units for chemical reactions as well as feeding and recycling the materials of a typical chemical process induces a vast amount of samples and subsequent prohibitive computation complexity in RL for deriving a suitable control policy due to high-dimensional state and action spaces. To tackle this problem, a novel RL algorithm: Factorial Fast-food Dynamic Policy Programming (FFDPP) is proposed. By introducing a factorial framework that efficiently factorizes the action space, Fast-food kernel approximation that alleviates the curse of dimensionality caused by the high dimensionality of state space, into Dynamic Policy Programming (DPP) that achieves stable learning even with insufficient samples. FFDPP is evaluated in a commercial chemical plant simulator for a Vinyl Acetate Monomer (VAM) process. Experimental results demonstrate that without any knowledge of the model, the proposed method successfully learned a stable policy with reasonable computation resources to produce a larger amount of VAM product with comparative performance to a state-of-the-art model-based control."
}
